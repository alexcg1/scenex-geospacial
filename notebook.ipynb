{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "59e984dc-e746-47f2-bdd1-700c51ce7600",
      "metadata": {
        "id": "59e984dc-e746-47f2-bdd1-700c51ce7600"
      },
      "source": [
        "# SceneXplain and geospatial data\n",
        "\n",
        "This notebook aims to test [SceneXplain](https://scenex.jina.ai)'s capabilities on land use classification.\n",
        "\n",
        "We used images from several land use datasets:\n",
        "\n",
        "- [UC Merced land use classification](http://weegee.vision.ucmerced.edu/datasets/landuse.html)\n",
        "- [AID (Aerial Image Dataset)](https://captain-whu.github.io/AID/)\n",
        "- [RESISC45 (Remote Sensing Image Scene Classification)](https://www.tensorflow.org/datasets/catalog/resisc45)\n",
        "\n",
        "After testing with sevetral algorithms, we saw the \"Flash\" algorithm offered the fastest performance and precision on par with more recent algorithms.\n",
        "\n",
        "Our results ranged from 60% to 80% accuracy.\n",
        "\n",
        "## Methodology\n",
        "\n",
        "### Pre-processing\n",
        "\n",
        "For each dataset, we selected a subset of 10 images from each category (for example, in the `airport` category we used the files `airport_01.jpg` to `airport_10.jpg`), and discarded the rest. So if a dataset had 20 categories that would give us 200 images in total to test.\n",
        "\n",
        "For each test, we specify a `MAX_COUNT` of images to test. If, say, the `MAX_COUNT` is 50, we randomly sample a total of 50 random images from random categories.\n",
        "\n",
        "All images were converted to JPEG format, since the original format was often TIFF which is unsupported by SceneXplain.\n",
        "\n",
        "All of this pre-processing was done in advance (i.e. not in this notebook), and processed files stored in the project's repo.\n",
        "\n",
        "### Classifying\n",
        "\n",
        "We classified the images files by using SceneXplain's \"Extract JSON from Image\" task, sending each image with a simple JSON schema that specified a `category` string, with potential choices in an `enum` containing dataset's categories.\n",
        "\n",
        "The JSON schema is as follows:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"category\": {\n",
        "      \"type\": \"array\",\n",
        "      \"description\": \"Which single main category of geospatial imagery does this image belong to?\",\n",
        "      \"enum\": [<categories from dataset>],\n",
        "      \"maxContains\": 1\n",
        "    }\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "A success condition was defined as the output category (output by SceneXplain) matching the target category (defined by the folder name). The score was determined by `successes`/(`successes`)+(`failures`). Any errors (e.g. timeouts) were excluded.\n",
        "\n",
        "## What happens when it goes wrong?\n",
        "\n",
        "There are several factors:\n",
        "\n",
        "- Several categories are very similar, e.g. `sparse_residential`, `medium_residential`, `dense_residential`. SceneXplain often picks the wrong one. This can also be seen in cases like `road` vs `runway`.\n",
        "- Occasionally it hallucinates a new category not specified in the `enum`, for example `residential`. Occasionally it glitches and assigns a category like `A`.\n",
        "- Some category names like `chaparral` ([a scrubland common in California](https://en.wikipedia.org/wiki/Chaparral)) are uncommon words and/or concepts. It seems unlikely that many pictures of (and references to) chaparral are used in training datasets.\n",
        "\n",
        "## Notes\n",
        "\n",
        "- The first section of this notebook is largely function definition and general set up.\n",
        "- We are using a subset of the full datasets, pre-processed for use with SceneXplain's API (e.g. resizing to manageable size, converting to common format, making directory structure consistent). For the sake of space and processing power, this is stored directly in our repo (otherwise there would be even more stuff in this notebook).\n",
        "- While SceneXplain offers batch processing, we simply use serial transmission in this notebook, since we need to send the image data and then compare SceneXplain's output with the target label. Doing this in a batched manner is surely possible, but would take longer to implement.\n",
        "\n",
        "## Before you start\n",
        "\n",
        "Get a [secret](https://scenex.jina.ai/api) to access SceneXplain's API and enter it below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "52245011-946e-4e11-b052-128a838a82bf",
      "metadata": {
        "id": "52245011-946e-4e11-b052-128a838a82bf"
      },
      "outputs": [],
      "source": [
        "SCENEX_SECRET = '<YOUR SECRET>'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ensure we're always using latest version by deleting whatever we've got and cloning from scratch\n",
        "!rm -rf scenex-geospatial"
      ],
      "metadata": {
        "id": "W4QHVPNe-aKl"
      },
      "id": "W4QHVPNe-aKl",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/alexcg1/scenex-geospatial.git\n",
        "\n",
        "import os\n",
        "os.chdir('scenex-geospatial')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDr-ojfuza6t",
        "outputId": "b0fc92bb-e9be-43cd-81a5-a9f6ae97fcdb"
      },
      "id": "fDr-ojfuza6t",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'scenex-geospatial'...\n",
            "remote: Enumerating objects: 1147, done.\u001b[K\n",
            "remote: Counting objects: 100% (2/2), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 1147 (delta 0), reused 1 (delta 0), pack-reused 1145\u001b[K\n",
            "Receiving objects: 100% (1147/1147), 85.61 MiB | 31.81 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import json\n",
        "import os\n",
        "import base64\n",
        "import http\n",
        "from random import sample\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "nVHBB0vizmPY"
      },
      "id": "nVHBB0vizmPY",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3e2ffa42-4784-48b5-b3e1-29d34f05749c",
      "metadata": {
        "id": "3e2ffa42-4784-48b5-b3e1-29d34f05749c"
      },
      "outputs": [],
      "source": [
        "# SceneXplain options\n",
        "FEATURES = ['json']\n",
        "ALGO = 'Flash'\n",
        "\n",
        "# Dataset options\n",
        "MAX_COUNT = 50"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get base schema for classification of images\n",
        "with open('base_schema.json') as file:\n",
        "    schema = json.loads(file.read())"
      ],
      "metadata": {
        "id": "Fxq5vXRT6v5_"
      },
      "id": "Fxq5vXRT6v5_",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d4c3bb82-f09e-4fd8-9569-ddbd355ad53e",
      "metadata": {
        "id": "d4c3bb82-f09e-4fd8-9569-ddbd355ad53e"
      },
      "outputs": [],
      "source": [
        "headers = {\n",
        "    \"x-api-key\": f\"token {SCENEX_SECRET}\",\n",
        "    \"content-type\": \"application/json\",\n",
        "\n",
        "}\n",
        "\n",
        "def image_to_data_uri(file_path: str):\n",
        "    with open(file_path, \"rb\") as image_file:\n",
        "        encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "        return f\"data:image/jpeg;base64,{encoded_image}\"\n",
        "\n",
        "\n",
        "def process_image(filename: str, schema: str, features: list=FEATURES):\n",
        "    print(f'Processing {filename}')\n",
        "    data = {\n",
        "        \"data\": [\n",
        "            {\n",
        "                \"image\": image_to_data_uri(filename),\n",
        "                \"algorithm\": ALGO,\n",
        "                \"features\": features,\n",
        "                \"json_schema\": json.dumps(schema),\n",
        "            },\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    connection = http.client.HTTPSConnection(\"api.scenex.jina.ai\")\n",
        "    connection.request(\"POST\", \"/v1/describe\", json.dumps(data), headers)\n",
        "    response = connection.getresponse()\n",
        "\n",
        "    response_data = response.read().decode(\"utf-8\")\n",
        "    response_json = json.loads(response_data)\n",
        "\n",
        "    connection.close()\n",
        "\n",
        "    return response_json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dataset(folder_name: str, schema: str, max_count: int):\n",
        "  image_files = glob.glob(f'{folder_name}/**/*.jpg')\n",
        "  shuffled_files = sample(image_files, max_count)\n",
        "  successes = []\n",
        "  fails = []\n",
        "  errors = []\n",
        "\n",
        "\n",
        "  for filename in shuffled_files:\n",
        "      category_name = filename.split('/')[-2]\n",
        "      image_data = process_image(filename=filename, schema=schema, features=FEATURES)\n",
        "      try:\n",
        "          scenex_category = json.loads(image_data['result'][0]['i18n']['en'])['category'][0]\n",
        "      except:\n",
        "          scenex_category = \"error processing\"\n",
        "\n",
        "      data = {\n",
        "          \"image_path\": filename,\n",
        "          \"target_category\": category_name,\n",
        "          \"scenex_category\": scenex_category\n",
        "      }\n",
        "\n",
        "      if data['target_category'] == data['scenex_category']:\n",
        "          data['match'] = True\n",
        "          successes.append(data)\n",
        "          print(\"\\t✅ Successful match!\")\n",
        "      elif data['scenex_category'] == 'error processing':\n",
        "          errors.append(data)\n",
        "          print(\"\\t😭 Error\")\n",
        "          pprint(image_data)\n",
        "      else:\n",
        "          data['match'] = False\n",
        "          fails.append(data)\n",
        "          print(f\"\\t❌ Failed match! (Identified {data['target_category']} as {data['scenex_category']})\")\n",
        "\n",
        "  # what percent did we get right?\n",
        "  score = len(successes)/(len(successes)+len(fails))\n",
        "\n",
        "  output = {\n",
        "      'algo': ALGO,\n",
        "      'features': FEATURES,\n",
        "      'score': score,\n",
        "      'dataset': folder_name,\n",
        "      'successes': successes,\n",
        "      'fails': fails,\n",
        "      'errors': errors\n",
        "  }\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "nmUSR9VO7HkD"
      },
      "id": "nmUSR9VO7HkD",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### UC Merced Dataset\n",
        "\n",
        "[UC Merced Land Use Dataset](http://weegee.vision.ucmerced.edu/datasets/landuse.html) is a 21 class land use image dataset meant for research purposes.\n",
        "\n",
        "For our testing we downloaded 10 images from each category and then sample a selection of that (defined by `MAX_COUNT`) for testing.\n",
        "\n",
        "The categories are: agricultural, airplane, baseball diamond, beach, buildings, chaparral, dense residential, forest, freeway, golf course, harbor, intersection, medium residential, mobile home park, overpass, parking lot, river, runway, sparse residential, storage tanks, tennis court."
      ],
      "metadata": {
        "id": "IfGcqYbs6VCd"
      },
      "id": "IfGcqYbs6VCd"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = \"./data/uc_merced\"\n",
        "\n",
        "# Create JSON schema - since each dataset may have different tags, we have to create it dynamically\n",
        "category_dirs = os.listdir(dataset)\n",
        "schema['properties']['category']['enum'] = category_dirs"
      ],
      "metadata": {
        "id": "ebmSroV_6g1S"
      },
      "id": "ebmSroV_6g1S",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uc_merced_output = process_dataset(dataset, schema, MAX_COUNT)"
      ],
      "metadata": {
        "id": "WvoRAG7Z7_b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e243346-acd0-4d97-f8e8-22e6e60c4d07"
      },
      "id": "WvoRAG7Z7_b2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./data/nwpu/meadow/meadow_006.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/intersection/intersection_009.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/thermal_power_station/thermal_power_station_003.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/river/river_001.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/railway_station/railway_station_007.jpg\n",
            "\t❌ Failed match! (Identified railway_station as railway)\n",
            "Processing ./data/nwpu/mobile_home_park/mobile_home_park_004.jpg\n",
            "\t❌ Failed match! (Identified mobile_home_park as residential_area)\n",
            "Processing ./data/nwpu/dense_residential/dense_residential_003.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/baseball_diamond/baseball_diamond_002.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/forest/forest_009.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/golf_course/golf_course_002.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/desert/desert_005.jpg\n",
            "\t❌ Failed match! (Identified desert as wood)\n",
            "Processing ./data/nwpu/baseball_diamond/baseball_diamond_008.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/church/church_008.jpg\n",
            "\t❌ Failed match! (Identified church as building)\n",
            "Processing ./data/nwpu/commercial_area/commercial_area_006.jpg\n",
            "\t❌ Failed match! (Identified commercial_area as dense_residential)\n",
            "Processing ./data/nwpu/rectangular_farmland/rectangular_farmland_002.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/church/church_010.jpg\n",
            "\t❌ Failed match! (Identified church as palace)\n",
            "Processing ./data/nwpu/railway_station/railway_station_009.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/rectangular_farmland/rectangular_farmland_004.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/industrial_area/industrial_area_007.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/ship/ship_007.jpg\n",
            "\t❌ Failed match! (Identified ship as harbor)\n",
            "Processing ./data/nwpu/thermal_power_station/thermal_power_station_002.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/roundabout/roundabout_002.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/harbor/harbor_003.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/golf_course/golf_course_003.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/palace/palace_004.jpg\n",
            "\t❌ Failed match! (Identified palace as harbor)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uc_merced_output['score']"
      ],
      "metadata": {
        "id": "tDsyhXTv519M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "182d92a2-d235-45f6-a20e-beed4c3c979f"
      },
      "id": "tDsyhXTv519M",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.68"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AID dataset\n",
        "\n",
        "[AID](https://captain-whu.github.io/AID/) is a large-scale aerial image dataset consisting of sample images from Google Earth imagery.\n",
        "\n",
        "The dataset is made up of the following 30 aerial scene types: airport, bare land, baseball field, beach, bridge, center, church, commercial, dense residential, desert, farmland, forest, industrial, meadow, medium residential, mountain, park, parking, playground, pond, port, railway station, resort, river, school, sparse residential, square, stadium, storage tanks and viaduct. All the images are labelled by the specialists in the field of remote sensing image interpretation.\n",
        "\n",
        "As with the other datasets in this notebook, we are using a small subset of 10 images per category for our testing."
      ],
      "metadata": {
        "id": "IRngp-faoXJL"
      },
      "id": "IRngp-faoXJL"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = \"./data/aid\"\n",
        "category_dirs = os.listdir(dataset)\n",
        "schema['properties']['category']['enum'] = category_dirs"
      ],
      "metadata": {
        "id": "iSpy7Fpyou2v"
      },
      "id": "iSpy7Fpyou2v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aid_output = process_dataset(dataset, schema, MAX_COUNT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPr6GBDYo01b",
        "outputId": "204bb8cc-d2a4-45f2-f4f9-edc822ca8f53"
      },
      "id": "gPr6GBDYo01b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./data/nwpu/mobile_home_park/mobile_home_park_002.jpg\n",
            "\t❌ Failed match! (Identified mobile_home_park as dense_residential)\n",
            "Processing ./data/nwpu/meadow/meadow_003.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/railway_station/railway_station_008.jpg\n",
            "\t❌ Failed match! (Identified railway_station as land)\n",
            "Processing ./data/nwpu/sea_ice/sea_ice_006.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/rectangular_farmland/rectangular_farmland_007.jpg\n",
            "\t❌ Failed match! (Identified rectangular_farmland as meadow)\n",
            "Processing ./data/nwpu/storage_tank/storage_tank_008.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/lake/lake_001.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/runway/runway_007.jpg\n",
            "\t❌ Failed match! (Identified runway as airport)\n",
            "Processing ./data/nwpu/snowberg/snowberg_009.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/beach/beach_001.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/intersection/intersection_007.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/meadow/meadow_007.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/roundabout/roundabout_008.jpg\n",
            "\t❌ Failed match! (Identified roundabout as r)\n",
            "Processing ./data/nwpu/storage_tank/storage_tank_010.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/airplane/airplane_007.jpg\n",
            "\t❌ Failed match! (Identified airplane as airport)\n",
            "Processing ./data/nwpu/dense_residential/dense_residential_010.jpg\n",
            "\t❌ Failed match! (Identified dense_residential as denseresidential)\n",
            "Processing ./data/nwpu/stadium/stadium_010.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/snowberg/snowberg_004.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/freeway/freeway_009.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/parking_lot/parking_lot_005.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/parking_lot/parking_lot_008.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/runway/runway_005.jpg\n",
            "\t❌ Failed match! (Identified runway as airport)\n",
            "Processing ./data/nwpu/railway/railway_001.jpg\n",
            "\t❌ Failed match! (Identified railway as forest)\n",
            "Processing ./data/nwpu/cloud/cloud_001.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/thermal_power_station/thermal_power_station_010.jpg\n",
            "\t❌ Failed match! (Identified thermal_power_station as industrial_area)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aid_output['score']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOqsibTYvAtT",
        "outputId": "e4ed8533-9b89-479e-e48f-13b3d32c6415"
      },
      "id": "kOqsibTYvAtT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NWPU RESISC45 dataset\n",
        "\n",
        "[RESISC45 dataset](https://github.com/tensorflow/datasets/blob/master/docs/catalog/resisc45.md) is a publicly available benchmark for Remote Sensing Image Scene Classification (RESISC), created by Northwestern Polytechnical University (NWPU). This dataset contains 31,500 images, covering 45 scene classes with 700 images in each class.\n",
        "\n",
        "For our testing we downloaded 10 images from each category and then sample a selection of that (defined by `MAX_COUNT`) for testing.\n",
        "\n",
        "The categories are: airplane, airport, baseball_diamond, basketball_court, beach, bridge, categories.txt, chaparral, church, circular_farmland, cloud, commercial_area, dense_residential, desert, forest, freeway, golf_course, ground_track_field, harbor, industrial_area, intersection, island, lake, meadow, medium_residential, mobile_home_park, mountain, overpass, palace, parking_lot, railway, railway_station, rectangular_farmland, river, roundabout, runway, sea_ice, ship, snowberg, sparse_residential, stadium, storage_tank, tennis_court, terrace, thermal_power_station, wetland"
      ],
      "metadata": {
        "id": "ksnVl206AIaI"
      },
      "id": "ksnVl206AIaI"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = \"./data/nwpu\"\n",
        "category_dirs = os.listdir(dataset)\n",
        "schema['properties']['category']['enum'] = category_dirs"
      ],
      "metadata": {
        "id": "xHs3SsFfANSO"
      },
      "id": "xHs3SsFfANSO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nwpu_output = process_dataset(dataset, schema, MAX_COUNT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NS3dysBwAXrW",
        "outputId": "1cfdcb96-877a-4bba-a9b8-34730f89e2bb"
      },
      "id": "NS3dysBwAXrW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./data/nwpu/harbor/harbor_007.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/forest/forest_002.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/beach/beach_007.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/roundabout/roundabout_002.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/runway/runway_003.jpg\n",
            "\t❌ Failed match! (Identified runway as roundabout)\n",
            "Processing ./data/nwpu/stadium/stadium_008.jpg\n",
            "\t❌ Failed match! (Identified stadium as soccer stadium)\n",
            "Processing ./data/nwpu/baseball_diamond/baseball_diamond_001.jpg\n",
            "\t❌ Failed match! (Identified baseball_diamond as airplane)\n",
            "Processing ./data/nwpu/stadium/stadium_001.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/rectangular_farmland/rectangular_farmland_010.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/railway/railway_002.jpg\n",
            "\t❌ Failed match! (Identified railway as railway_station)\n",
            "Processing ./data/nwpu/sparse_residential/sparse_residential_004.jpg\n",
            "\t❌ Failed match! (Identified sparse_residential as rectangular_farmland)\n",
            "Processing ./data/nwpu/overpass/overpass_007.jpg\n",
            "\t❌ Failed match! (Identified overpass as intersection)\n",
            "Processing ./data/nwpu/overpass/overpass_002.jpg\n",
            "\t❌ Failed match! (Identified overpass as intersection)\n",
            "Processing ./data/nwpu/railway/railway_005.jpg\n",
            "\t❌ Failed match! (Identified railway as railway_station)\n",
            "Processing ./data/nwpu/dense_residential/dense_residential_006.jpg\n",
            "\t❌ Failed match! (Identified dense_residential as sparse_residential)\n",
            "Processing ./data/nwpu/ship/ship_007.jpg\n",
            "\t❌ Failed match! (Identified ship as harbor)\n",
            "Processing ./data/nwpu/lake/lake_001.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/thermal_power_station/thermal_power_station_006.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/beach/beach_005.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/rectangular_farmland/rectangular_farmland_005.jpg\n",
            "\t❌ Failed match! (Identified rectangular_farmland as farmland)\n",
            "Processing ./data/nwpu/mobile_home_park/mobile_home_park_009.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/ground_track_field/ground_track_field_010.jpg\n",
            "\t❌ Failed match! (Identified ground_track_field as parking_lot)\n",
            "Processing ./data/nwpu/railway_station/railway_station_009.jpg\n",
            "\t❌ Failed match! (Identified railway_station as airplane)\n",
            "Processing ./data/nwpu/sea_ice/sea_ice_006.jpg\n",
            "\t✅ Successful match!\n",
            "Processing ./data/nwpu/lake/lake_004.jpg\n",
            "\t✅ Successful match!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nwpu_output['score']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiUW4IzYAfgu",
        "outputId": "f021ac29-e2fe-4801-97cf-ca18570b53bf"
      },
      "id": "oiUW4IzYAfgu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.48"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}